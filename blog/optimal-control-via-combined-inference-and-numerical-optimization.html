<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<title>Optimal Control via Combined Inference and Numerical Optimization</title>
<meta name="description" content="Thesis segment blog post"/>
<link rel="stylesheet" href="../css/site-common.css" type="text/css"/>
<link rel="stylesheet" href="../css/blog-post.css" type="text/css"/>
<link rel="stylesheet" href="../css/blog-post-optimal.css" type="text/css"/>
<script>
window.MathJax = {
  tex: {
    inlineMath: [['\\(', '\\)']],
    displayMath: [['\\[', '\\]']],
    macros: {
      vec: ['\\mathbf{#1}', 1]
    }
  },
  svg: { fontCache: 'global' }
};
</script>
<script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</head>
<body>
  <main role="main">
    <div class="container">
      <p class="back"><a href="/blog/">&larr; Back to blog index</a></p>
      <header class="page-header">
        <h1>Optimal Control via Combined Inference and Numerical Optimization</h1>
      </header>

      <section class="section">

        <h3>Problem statement</h3>
        <p>Numerical optimisation is efficient at refinement but fails to <strong>discover</strong> control policies or behaviours far from the point of initialisation. Sampling can discover further local optima through exploration with simpler cost functions.</p>
        <p><strong>Aim.</strong> Combine inference and second-order trajectory optimization so the method can <strong>efficiently sample</strong> when <em>no derivative information</em> is available and follow <strong>optimized trajectories</strong> when derivatives arise.</p>

        <h3>Numerical solution</h3>
        <p>The method relies on the Bellman equation and its tangent-space solution.</p>
        <div class="equation">
          \[
          v\left(\mathbf{x}, t\right) = \min_{\mathbf{u}}\left[\ell\left(\mathbf{x},\mathbf{u},t\right) + v\left(\mathbf{f}\left(\mathbf{x},\mathbf{u},t\right)\right)\right] \equiv Q\left(\mathbf{x},\mathbf{u},t\right)
          \]
        </div>
        <p>Solving in tangent space:</p>
        <div class="equation">
          \[
          Q\left(\delta\mathbf{x},\delta\mathbf{u}\right) \approx \frac{1}{2}
          \begin{bmatrix}1 \\ \delta\mathbf{x} \\ \delta\mathbf{u}\end{bmatrix}^{\!\top}
          \begin{bmatrix}
          0 & Q_{\mathbf{x}}^{\top} & Q_{\mathbf{u}}^{\top} \\
          Q_{\mathbf{x}} & Q_{\mathbf{xx}} & Q_{\mathbf{xu}} \\
          Q_{\mathbf{u}} & Q_{\mathbf{ux}} & Q_{\mathbf{uu}}
          \end{bmatrix}
          \begin{bmatrix}1 \\ \delta\mathbf{x} \\ \delta\mathbf{u}\end{bmatrix}
          \]
        </div>
        <p>Update law (Newton-like):</p>
        <div class="equation">
          \[
          \hat{\mathbf{u}} = \mathbf{u} - \left(Q_{\mathbf{u}} - Q_{\mathbf{ux}}\delta\mathbf{x}\right)Q^{-1}_{\mathbf{uu}}
          \]
        </div>

        <h3>Inference solution</h3>
        <p>The KL control approach is grounded in the stochastic version of the Bellman equation.</p>
        <div class="equation">
          \[
          \begin{gathered}
          \underset{\mathbf{u}}{\min}\left[\ell\left(\mathbf{x}\right) + \mathrm{KL}(\mathcal{Q}\|\|\mathcal{P}) + \mathbb{E}_{\mathcal{Q}}\left[v\left(\mathbf{x}'\right)\right]\right]\\
          \mathrm{KL}(\mathcal{Q}\|\|\mathcal{P}) = \mathbb{E}_{\mathcal{Q}}\!\left[\log\!\left(\frac{\mathbf{p}\left(\mathbf{x}'|\mathbf{x},\mathbf{u}\right)}{\mathbf{p}\left(\mathbf{x}'|\mathbf{x}\right)}\right)\right]
          \end{gathered}
          \]
        </div>
        <p>Where \(\mathbf{p}\left(\mathbf{x}'|\mathbf{x},\mathbf{u}\right)\) and \(\mathbf{p}\left(\mathbf{x}'|\mathbf{x}\right)\) are the controlled and uncontrolled transition probabilities.</p>
        <p>Optimal controls:</p>
        <div class="equation">
          \[
          \mathbf{p}^*\left(\mathbf{x}'|\mathbf{x},\mathbf{u}\right) = \mathbf{p}\left(\mathbf{x}'|\mathbf{x}\right)\exp\left(-v\left(\mathbf{x}'\right)\right)\eta^{-1}
          \]
        </div>

        <h3>Combining inference with second order method</h3>
        <p>Reformulate the stochastic Bellman objective and add a secondary divergence term to the tangent-space Bellman solution.</p>
        <div class="equation">
          \[
          \begin{gathered}
          \underset{\mathbf{u}}{\min}\left[l\left(\mathbf{x}\right) + (1-k)\,\mathrm{KL}(\mathcal{Q}\|\|\mathcal{P}) + k\,\mathrm{KL}(\mathcal{Q}\|\|\mathcal{C}) + \mathbb{E}_{\mathcal{Q}}\left[v\left(\mathbf{x}'\right)\right]\right]\\
          \mathrm{KL}(\mathcal{Q}\|\|\mathcal{C}) = \mathbb{E}_{\mathcal{Q}}\!\left[\log\!\left(\frac{\mathbf{p}\left(\mathbf{x}'|\mathbf{x},\mathbf{u}\right)}{\mathbf{p}\left(\mathbf{x}'|\mathbf{x},\mathbf{u}_{\mathrm{iLQG}}\right)}\right)\right]
          \end{gathered}
          \]
        </div>
        <p>Update law over trajectory distribution:</p>
        <div class="equation">
          \[
          \mathbf{q}^*\left(\mathbf{W}\right) = \mathbf{p}\left(\mathbf{W}\right)^{1-k}\mathbf{c}\left(\mathbf{W}\right)^{k}\exp\!\left(-\frac{1}{\lambda}S\left(\mathbf{W}\right)\right)\eta^{-1}
          \]
        </div>
        <div class="equation">
          \[
          \mathbf{p}\left(\mathbf{W}\right):\mathbf{w}_t\sim\mathcal{N}\left(0,\mathbf{\Sigma}\right),\quad
          \mathbf{q}\left(\mathbf{W}\right):\mathbf{w}_t\sim\mathcal{N}\left(\mathbf{u}_t,\mathbf{\Sigma}\right),\quad
          \mathbf{c}\left(\mathbf{W}\right):\mathbf{w}_t\sim\mathcal{N}\left(\mathbf{u}_{\mathrm{iLQG}_t},\mathbf{\Sigma}_{\mathrm{iLQG}}\right)
          \]
        </div>

        <h3>Importance sampling</h3>
        <p>We cannot directly sample from \(\mathbf{q}^*(\vec W)\), so we importance sample:</p>
        <div class="equation">
          \[
          \mathbf{u}^* = \int \mathbf{q}\left(\vec W\right)\,w\left(\vec W\right)\,v_t\,\mathrm{d}W
          \]
        </div>
        <p>Sample weights:</p>
        <div class="equation">
          \[
          w\left(\vec W\right) = \frac{1}{\eta}\exp\!\left(-\frac{1}{2\lambda}S\left(\vec W\right)
          + \sum_{t=0}^{T}k\,\left(\vec w_t-\mathbf{u}_{\mathrm{iLQG}_t}\right)^\top
          \mathbf{\Sigma}_{\mathrm{iLQG}_t}^{-1}\left(\vec w_t-\mathbf{u}_{\mathrm{iLQG}_t}\right)\right)
          \]
        </div>
        <p>iLQG distribution is obtained by maximizing \(\ln\exp\left(-\delta Q_t\left(\mathbf{x}_t,\mathbf{u}_t\right)\right)\), with samples from \(\mathcal{C}\) as \(\vec w_t\sim\mathcal{N}\left(\mathbf{u}_{\mathrm{iLQG}_t},Q^{-1}_{\mathbf{uu}_t}\right)\).</p>

        <h3>Results</h3>
        <video class="result-video" controls preload="metadata">
          <source src="value%20learning%20content/ICRA.mp4" type="video/mp4"/>
          Your browser does not support the video tag.
        </video>

        <h3>Conclusion</h3>
        <div class="conclusion-grid">
          <div class="conclusion-block">
            <h4>Contribution</h4>
            <ul>
              <li>Natural combination of inference and numerical optimisation.</li>
              <li>Inherent ability to explore.</li>
              <li>Combine convex and non-convex costs.</li>
            </ul>
          </div>
          <div class="conclusion-block">
            <h4>Caveats</h4>
            <ul>
              <li>Search across hyperparameters: \(\lambda\), \(\beta\), and \(k\).</li>
              <li>\(Q_{uu}^{-1}\) is not necessarily a good measure of confidence.</li>
              <li>Constant control input noise affects convergence.</li>
              <li>In the worst case, it can perform as badly as the other methods.</li>
            </ul>
          </div>
        </div>
      </section>
    </div>
  </main>
</body>
</html>
